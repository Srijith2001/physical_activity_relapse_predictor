{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "As our dataset is now ready we shall use Ensemble Classifier algorithms to train the model\n",
    "\n",
    "Since there are various different models, we shall try all of them one by one.\n",
    "\n",
    "Let us load the dataset and split it for training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('../new_type/t_dataset.csv',index_col=0)\n",
    "y = dataset.DiPS\n",
    "features = ['Initial Steps','Average Steps','Last Week Steps','Week Number']\n",
    "x = dataset[features]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=50,shuffle=True)\n",
    "dataset"
   ]
  },
  {
   "source": [
    "## Bagging Algorithms\n",
    "\n",
    "### 1. Bagged Decision Trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Initialize model and train it.\n",
    "kfold = model_selection.KFold(n_splits=70)\n",
    "cart = DecisionTreeClassifier()\n",
    "b_model = BaggingClassifier(base_estimator=cart, n_estimators=100, random_state=1)\n",
    "b_model.fit(x_train,y_train)\n",
    "\n",
    "# Find the mean prediction rate\n",
    "b_results = model_selection.cross_val_score(b_model, x_train, y_train, cv=kfold,scoring='roc_auc')\n",
    "b_scores = b_model.predict(x_test)\n",
    "\n",
    "print(b_results.mean())\n",
    "\n",
    "#Plot ROC Curve\n",
    "plot_roc_curve(b_model, x_test, y_test,color ='darkorange',linewidth=3,label='EnsembleClassifier (auc=%.2f)'%roc_auc_score(y_test,y_pred_proba))\n",
    "plt.xlabel('1 - Specificity',size=13)\n",
    "plt.ylabel('Sensitivity',size=13)\n",
    "plt.title('Receiver Operating Characteristic',size=15)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix,plot_roc_curve\n",
    "#Initialize model and train it.\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "r_model = RandomForestClassifier(n_estimators=100, max_features=4)\n",
    "r_model.fit(x_train,y_train)\n",
    "\n",
    "# Find the mean prediction rate\n",
    "r_results = model_selection.cross_val_score(r_model, x_train, y_train, cv=kfold,scoring='roc_auc')\n",
    "print(r_results.mean())\n",
    "\n",
    "r_model.fit(x_train,y_train)\n",
    "r_scores = r_model.predict_proba(x_test)[::,1]\n",
    "# print(\"Accuracy:\",accuracy_score(y_test,r_scores))\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, r_scores)\n",
    "print('roc_auc_score for DecisionTree: ', roc_auc_score(y_test, r_scores))\n",
    "# print(confusion_matrix(y_test,r_scores))\n",
    "plot_roc_curve(r_model, x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix,plot_roc_curve,accuracy_score\n",
    "\n",
    "#Initialize model and train it.\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "e_model = ExtraTreesClassifier(n_estimators=100, max_features=4)\n",
    "\n",
    "# Find the mean prediction rate\n",
    "e_results = model_selection.cross_val_score(e_model, x_train, y_train, cv=kfold,scoring='roc_auc')\n",
    "print(e_results.mean())\n",
    "\n",
    "e_model.fit(x_train,y_train)\n",
    "e_scores = e_model.predict_proba(x_test)[::,1]\n",
    "# print(\"Accuracy:\",accuracy_score(y_test,e_scores))\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, e_scores)\n",
    "print('roc_auc_score for DecisionTree: ', roc_auc_score(y_test, e_scores))\n",
    "# print(confusion_matrix(y_test,e_scores))\n",
    "plot_roc_curve(e_model, x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Algorithms\n",
    "\n",
    "### 1. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix,plot_roc_curve,accuracy_score\n",
    "\n",
    "\n",
    "#Initialize model and train it.\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "ab_model = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Find the mean prediction rate\n",
    "ab_results = model_selection.cross_val_score(ab_model, x_train, y_train, cv=kfold,scoring='roc_auc')\n",
    "print(ab_results.mean())\n",
    "\n",
    "ab_model.fit(x_train,y_train)\n",
    "ab_scores = ab_model.predict_proba(x_test)[::,1]\n",
    "# print(\"Accuracy:\",accuracy_score(y_test,ab_scores))\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, ab_scores)\n",
    "print('roc_auc_score for DecisionTree: ', roc_auc_score(y_test, ab_scores))\n",
    "# print(confusion_matrix(y_test,ab_scores))\n",
    "plot_roc_curve(ab_model, x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#Initialize model and train it.\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=5)\n",
    "\n",
    "# Find the mean prediction rate\n",
    "gb_results = model_selection.cross_val_score(gb_model, x_train, y_train, cv=kfold,scoring='roc_auc')\n",
    "print(gb_results.mean())\n",
    "\n",
    "# Plot ROC Curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix,plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gb_model.fit(x_train,y_train)\n",
    "gb_scores = gb_model.predict_proba(x_test)[::,1]\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, gb_scores)\n",
    "print('roc_auc_score for DecisionTree: ', roc_auc_score(y_test, gb_scores))\n",
    "plot_roc_curve(gb_model, x_test, y_test) \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "\n",
    "# Create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "\n",
    "# Find the mean prediction rate\n",
    "ve_results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold,scoring='roc_auc')\n",
    "print(ve_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have tried various different ensemble classifiers, let us summarize the prediction accuracy of each model.\n",
    "\n",
    "## Summary\n",
    "\n",
    "Here we compare the accuracy of various ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Mean Prediction Accuracy of various models:\")\n",
    "print(\"\\nBagging Algorithms\")\n",
    "print(\"1. Bagged Decision Trees: \",b_results.mean())\n",
    "print(\"2. Random Forest: \",r_results.mean())\n",
    "print(\"3. Extra Trees: \",e_results.mean())\n",
    "print('\\nBoosting Algorithms')\n",
    "print(\"1. AdaBoost: \",ab_results.mean())\n",
    "print(\"2. Stochastic Gradient Boosting \",gb_results.mean())\n",
    "print('\\nVoting Ensemble:',ve_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "x = ['BaggedDecisonTree','RandomForest','ExtraTrees','AdaBoost','StochasticGradient','VotingEnsemble']\n",
    "y = [b_results.mean()*100,r_results.mean()*100,e_results.mean()*100,ab_results.mean()*100,gb_results.mean()*100,ve_results.mean()*100]\n",
    "low = min(y)-2\n",
    "high = max(y)\n",
    "plt.ylim([math.ceil(low-0.5*(high-low)), math.ceil(high+0.5*(high-low))])\n",
    "# creating the bar plot\n",
    "plt.bar(x, y, color =['red','blue','green','orange','cyan','maroon'],width = 0.5)\n",
    " \n",
    "# for index, value in enumerate(y):\n",
    "#      plt.text(value, index,\n",
    "#               str(value))\n",
    "    \n",
    "plt.xlabel(\"Ensemble Classifier Models\")\n",
    "plt.ylabel(\"Mean Accuracy %\")\n",
    "plt.title(\"Accuracy of different ensemble models\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Linear Regression\n",
    "\n",
    "Let us find out the accuracy of LR on the same dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "log_scores = logreg.score(x_test,y_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))"
   ]
  },
  {
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Let us check how the svm classifier performs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "dataset = pd.read_csv('../new_type/t_dataset.csv')\n",
    "y = dataset.DiPS\n",
    "features = ['Initial Steps','Average Steps','Last Week Steps','Week Number']\n",
    "X = dataset[features]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "sv_score = model.score(x_test,y_test)\n",
    "print('Accuracy of support vector machine on test set: {:.2f}'.format(model.score(x_test, y_test)))"
   ]
  },
  {
   "source": [
    "## Comparsion\n",
    "\n",
    "Let us plot the different accuracy using matplot lib"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x= ['SVM', 'LR', 'EM']\n",
    "y = [sv_score*100,log_scores*100,gb_results.mean()*100]\n",
    "fig, ax = plt.subplots()\n",
    "low = min(y)-2\n",
    "high = max(y)\n",
    "plt.xlim([math.ceil(low-0.5*(high-low)), math.ceil(high+0.2*(high-low))])\n",
    "width = 0.75 # the width of the bars \n",
    "ind = np.arange(len(y))  # the x locations for the groups\n",
    "ax.barh(ind, y, width, color=[\"blue\",'green','maroon'])\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(x, minor=False,Fontsize=12)\n",
    "for i, v in enumerate(y):\n",
    "    ax.text(v + 1, i , str(v)[:5], color='blue', fontweight='bold')\n",
    "plt.xlabel('Accuracy')  \n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}